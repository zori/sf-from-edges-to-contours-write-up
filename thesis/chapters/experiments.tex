\chapter{Experimental Results}
\label{Chapter5}

We conducted a number of experiments to show that adaptation to new conditions is an important and required technique for situations when the underlying
class-distribution changes over time. First, we start by experiments on the Random Forests to figure out the effect of different parameters
and to show that Random Forests are inherently robust to noisy labels.

Then we continue by comparing our implementations of methods described in Chapter~\ref{Chapter3} on the MSRC dataset. We do it to investigate
how different approaches perform relative each other and the state-of-the-art for general purpose image segmentation. Our main aim here
was to find an approach which would have good accuracy, but also low training and testing time, because we needed this classifier to be used in
on-line learning, which we chose to be our way of performing adaptation.

We conduct several experiments on the new dataset proposed in Chapter~\ref{Chapter4}. We compare the performance of the state-of-the-art method
for general purpose segmentation on this new dataset and the old one from~\cite{Wojek2008}. We show that existing datasets try to avoid difficult
visual conditions and that some standard approaches which do not perform adaptation to changing distribution tend to fail there.

In the end, we carried out a number of experiments with on-line learning methods described in Chapter~\ref{chapter_online}. We show that even
a naive on-line learning approach can improve segmentation results compared to standard approaches. We also show that our proposed
Bayesian Model Update under Structured Scene Prior allows to adapt to changing visual conditions and as a result to improve segmentation results.

\section{Experiments with Random Forests}
Random Forests have become very popular recently in image segmentation \cite{Brostow2008, Shotton2008, Kontschieder2011} for having good accuracy
and low training and testing time, being robust to noise. To check these properties we conducted the following experiments.

\subsection{Effect of Different Parameters}
\label{subsec:rf_and_parameters}
Usually in practice the minimum number of samples in a leaf node is set to quite a small number 3-5 and the parameter 
$ K $ is set to $ \lceil\sqrt{d}\rceil$. So, the only parameters which are adjusted in a particular application task
are the number of trees $M$ in a Random Forest and the maximum depth of each tree $ D $.

We studied the behavior of Random Forest by conducting the following experiment on the MSRC~\cite{MSRC} dataset. 
We used the same splitting of the dataset as in~\cite{Krahenbuhl2011} with the only difference that we added Validation set to the Training one.
Then we trained and tested Random Forest the following combinations of parameters: 
\begin{equation}
 S_p = D \times M,
\end{equation}
where $D = \{10, 12, 14, 16, 18\}, M = \{5, 10, 15, 20, 25, 30\}$.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth] {images/error_vs_params}
  \caption[Dependency of Test Error of Random Forest on parameters]{{\bf Dependency of Test Error of Random Forest on parameters}. 
  }
  \label{fig:error_vs_params}
\end{figure}

Figure~\ref{fig:error_vs_params} shows how Test Error changes with the change of parameters. The main observation here
is that by increasing both the maximum depth $D$ and the number of trees in the ensemble $M$ the Test Error goes down.
But parameter $D$ tends to have greater contribution in the decrease of the error. This is due to the fact that by
increasing $D$ we allow exponentially more splits to be done which allows for the trees to perform better separation of
the samples. But this also exponentially increases the size the Random Forest occupies in memory. But, in general,
large parameters $D$ or $M$ are not required as Random Forest converge pretty quickly and further increase in parameters does not 
necessarily results in corresponding increase in accuracy, but definitely increases required memory. For example, \cite{Shotton2011}
use only 3 trees but each of depth 20 and \cite{Shotton2008} use 5 trees each of depth 10.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth] {images/train_time_vs_params}
  \caption[Dependency of Training time of Random Forest on parameters]{{\bf Dependency of Training time of Random Forest on parameters}. 
  }
  \label{fig:train_time_vs_params}
\end{figure}

Figure~\ref{fig:train_time_vs_params} shows the dependency of training time on the parameters. This are times for multi-threaded
implementation with the help of Intel~TBB~\cite{IntelTBB}. Training time depends almost linearly on either of the parameters.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth] {images/test_time_vs_params}
  \caption[Dependency of Testing time of Random Forest on parameters]{{\bf Dependency of Testing time of Random Forest on parameters}. 
  }
  \label{fig:test_time_vs_params}
\end{figure}

Figure~\ref{fig:test_time_vs_params} shows how test time depends on different parameters. Again, the dependency is almost linear in
either of the parameters. The number of test images here was 256, so there is a whole bunch of parameters which allow for the
test time to be less than a second, which can be called real-time performance, yet showing almost optimal accuracy.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth] {images/running_time_vs_error}
  \caption[Running time \vs Test Error for Random Forests]{{\bf Running time \vs Test Error for Random Forests}. 
  }
  \label{fig:running_time_vs_error}
\end{figure}

Figure~\ref{fig:running_time_vs_error} shows the overall Running time for a Random Forest classifier \vs the Test Error. Here
Running time is a sum of Training and Testing time for the corresponding pair of parameters. Obviously, making Random Forests
larger and deeper allows to decrease generalization error, but results in corresponding increase of the Running time. It is
remarkable that Random Forests tend to converge rather quickly and further increase of parameters does not bring
noticeable decrease of Test Error, while considerably (after some point already exponentially in dependency of Test Error)
increase the overall Running time.

\subsection{Robustness to Noise}
\label{subsec:robust_to_noise}
In has been noticed~\cite{Breiman2001, Geurts2006} that Random Forests are particularly robust to errors in the provided
labels. The main reason for this behavior is that Random Forest does not try to find exact dependency between features and
labels. When trying to find an optimal split at each splitting node, it basically works only with features and only then
computes distribution of labels in the resulting splits. So, a moderate number of incorrectly provided labels will (hopefully)
not distract the distribution so much, that the decision about the best split will be done incorrectly.

To test this property we conducted the following experiment. We took a subset (around 2000 images with each class having around 
the same number of images) of USPS~\cite{USPS} dataset which consists of images of handwritten number from 0 to 9 (some examples
can be seen in Figure~\ref{fig:usps_examples}). 

\input{large_figures/usps_examples_figure.tex}

Then we randomly permuted
labels for a portion of the training data, train several classifiers and tested on a non-permuted test-set. The results can be seen
in Figure~\ref{fig:rf_vs_boosting}. On the X-axis you can see how many samples from the training data-set were changed their labels and
on the Y-axis test error (averaged over 5 independent runs) of each of the classifiers trained on the whole train data set with the 
corresponding number of changed labels.
We compared here GentleBoost classifier with 100 and 1000 weak learners and a Random Forest with 100 trees each
of depth 15. L. Breiman~\cite{Breiman2001} agues that for example ``AdaBoost is essentially Random Forest''. He states that
the number of iterations of Boosting roughly corresponds to the number of trees in a Random Forest. That is why we chose one
GentleBoost with 100 weak learners as a direct competitor of our implementation of Random Forest with 100 Random Trees
and also one GentleBoost with 1000 weak learners as even a higher challenge for the Random Forest classifier.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth] {images/rf_vs_boosting}
  \caption[Random Forest \vs GentleBoost on noisy train data]{{\bf Random Forest \vs GentleBoost on noisy train data}. 
  }
  \label{fig:rf_vs_boosting}
\end{figure}

As it follows from the Figure~\ref{fig:rf_vs_boosting}, Random Forest is indeed very robust to noise.
Even when around half of all the training samples are basically noise, it still shows reasonably good performance 
being more than 4 time better than GentleBoost.

Good robustness to noise of Random Forest was one of the main reasons why we eventually decided to use exactly
Random Forests as the basis classifier in this work.

\subsection{Discussion}
Random Forests show good convergence rates and allow to get good performance for already small number of trees, which allows to perform fast training
and testing using them. And this is particularly important for our application, because we need to perform re-training of the classifier preferably
in real-time in our on-line learning approaches. And low test-time is a crucial property for real-world application, because there the segmentation
of new images must be carried out in as little time as possible to ensure the least latency, because this will allow to use such classifier in
systems which should be able to analyze and react in real-time. In these and the following experiments we made an observation that
if the parameter setting of $M = 10, D = 15$ does not result in the expected accuracy then it is worth to rather consider further engineering
in features or some other aspects, than trying to tune parameters of the Random Forest.

Robustness to noise is a very useful property in our application, because in on-line learning approaches we use samples with predicted labels
which might exhibit a certain level of label noise. The on-line learning algorithms on their own try to minimize the number of wrong labels,
but it is good that already the classifier is robust to noise, thus making the overall system even more stable.

\section{Experiments on the MSRC dataset}
\label{msrc_experiments}

In the next step of our research we implemented a number of image segmentation algorithms showing good performance in the original papers and which
we think are suitable for our purposes. We needed to check several possibilities for the classifier and choose the best one from the point of view
of the trade-off between accuracy and speed. We would like to stress that we would prefer a faster working classifier, because we need as low as
possible running time in order to use this classifier later for on-line learning and we are also aiming for the real-world application, which
requires the whole system to be able to perform in real-time.
We carried out all experiments on the MSRC~\cite{MSRC} dataset, because this is the dataset used in all the original papers,
which describe the segmentation algorithms we employ in this work. And this dataset is just a de facto standard for comparing general
purpose image segmentation algorithms.

We used Random Forest as a classifier in all our implementations. We started with just Random Forest which
was working on individual pixels and CIE color values (Section~\ref{msrc_setting_1}). In Section~\ref{msrc_setting_1} we expanded the classifier to be able to work on feature patches 
around a pixel
(Figure~\ref{fig:feature_patch}). After that we added method of~\cite{Kontschieder2011} to improve output labeling and make 
it looking more consisting,
as this method allows to significantly decrease the level of noisy labels (Section~\ref{msrc_setting_3}). We also implemented 
algorithm of~\cite{Shotton2009} (Section~\ref{msrc_setting_4}), because their textons
are used in~\cite{Krahenbuhl2011} and the latter is currently state-of-the-art algorithm showing the best result on the MSRC~\cite{MSRC} dataset.
Finally, we apply Fully-Connected CRF approach from~\cite{Krahenbuhl2011} (Section~\ref{msrc_setting_5}), which improves not only visual segmentation results, but also considerably
decreases the Test error (we use the code, kindly provided by the authors). We use the standard for this dataset splitting into train and
test images from~\cite{Krahenbuhl2011} which can be found here
\url{http://graphics.stanford.edu/projects/densecrf/textonboost/split.zip}, with the only difference that we combine Train and
Validation sets together.

\begin{table}[t]
 \centering
 \begin{tabular}{|l|c|c|c|c|}
  \hline
  Method & \begin{tabular}[c]{@{}c@{}}Total\\error, \%\end{tabular} & \begin{tabular}[c]{@{}c@{}}Average\\error, \%\end{tabular} & Training time & Testing time \\
  \hline
  Random Forest & 56.3 & 77.5 & {\bf 19.65s} & 1m 5.1s \\
  \hline
  RF on feature patches & 47 & 69.4 & 51.64s & 1m 24.1s \\
  \hline
  SCL & 45.7 & 69.3 & 1m 10.1s & 2m 40.35s \\
  \hline
  RF with Texton features & 37.1 & 44.6 & 13m 44.3s & {\bf 36.83s} \\
  \hline
  Above + FC-CRF & 26.9 & 36.6 & 13m 44.3s & 4m 4.86s \\
  \hline
  \hline
  Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011} & {\bf 14.2} & {\bf 21.6} & \multicolumn{2}{c|}{around 1 day overall} \\
  \hline
 \end{tabular}
 \caption{Comparison of our implementations of methods described in Chapter~\ref{Chapter3} on the MSRC~\cite{MSRC} dataset. Detailed description
 of the experimental settings can be found in~\ref{msrc_experiments}.}
 \label{tab:msrc_comparison}
\end{table}

All our implementations were using Random Forest as the basis classifier. The parameters were set to: number of trees in the ensemble $M = 10$,
the maximum depth of each tree $D = 15$, number of random samples given to each tree was around $\frac{1}{4}$ of all the samples in the training set,
unless stated otherwise the number of random split tries per splitting node was set to the default value of $\lceil\sqrt{d}\rceil$. As it is common
for all experiments on the MSRC~\cite{MSRC} dataset, we used the stride of 5 pixels in each dimension. We used simplest CIE color values as features,
as we were mostly interested to see how different algorithms perform in the same conditions.
Numerical comparison of different experimental settings can be seen in Table~\ref{tab:msrc_comparison}.

It is worth mentioning that the performance numbers of all the methods can be increased by simply training more trees, or making them deeper, or by
changing other parameters of the classifier. But we were interested in performance numbers relative to each of the settings, but not the absolute
performance numbers.

\subsection{Setting 1: Pure Random Forest}
\label{msrc_setting_1}
In this experiment we trained a Random Forest which considered only local information of each pixel independently of the others. This is the most naive
among all possible approaches, but even such a simple method shows results which are significantly better than random guessing. 
Images, which show more or less correct labelings, still suffer from high labeling noise, mainly because in this case the classifier works on individual
pixels and does not consider any interactions between pixels.

Figure~\ref{fig:msrc_rf} shows some example outputs of this approach. An interesting observation is that even the most simple Random Forest is able
to locate objects in the scene and very accurately follow their borders. But unfortunately it makes a lot of mistakes when trying to predict class-labels
for segmented objects. So, just Random Forest can be used to successfully perform image segmentation, but not the semantic one.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/1_9_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/1_9_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/1_9_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/2_14_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/2_14_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/2_14_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/10_31_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/10_31_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/10_31_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/17_6_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/17_6_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/17_6_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/20_6_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/20_6_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/msrc_rf/20_6_s_cl}
 \end{subfigure}
 \caption{Columns denote from left to right: original image, ground truth image, output labeling of Random Forest~\ref{msrc_setting_1}.}\label{fig:msrc_rf}
\end{figure}


\subsection{Setting 2: Random Forest with Feature Patches}
\label{msrc_setting_2}

Allowing the Random Forest classifier to work on some neighborhood (Figure~\ref{fig:feature_patch}) in the feature space around each pixel 
allows to considerably improve segmentation
accuracy, even without modifying the features themselves. Apart from taking raw feature value from one of the neighboring pixels we also made use
of functions described in~\ref{raw_features}. Though feature patches do not modify the features themselves, but the change the way the 
classifier works with pixels and allows for it to capture,
for example, long-distance gradients which are more distinctive than just pixel's color values.

Third column of Figure~\ref{fig:msrc_scl} shows some results of this approach. This approach can nicely segment large objects in the images,
but it still produces a lot of noise in the output labelings.

In this experiment the number of random splits per split node was set to 
$K = \lceil\sqrt{d w^2}\rceil$, where $d = 3$ is the dimensionality of he original feature space and $w = 25$ is the dimensions of a square
feature patch around each pixel, to reflect the increased feature space dimensionality.

\cite{Shotton2008} report Total Error of 50.3\%. Our result is a bit better, because in~\cite{Shotton2008} they trained 5 trees each of maximum depth 10.

\subsection{Setting 3: Random Forest with Feature Patches and Structured Class-Labels}
\label{msrc_setting_3}

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/1_9_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/1_9_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/noisy/1_9_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/1_9_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/3_26_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/3_26_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/noisy/3_26_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/3_26_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/3_29_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/3_29_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/noisy/3_29_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/3_29_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/17_17_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/17_17_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/noisy/17_17_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/17_17_s_cl}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/17_19_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/17_19_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/noisy/17_19_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/scl/17_19_s_cl}
 \end{subfigure}
 \caption{Columns denote from left to right: original image, ground truth image, output labeling of Random Forest with feature patches~\ref{msrc_setting_2},
 output labeling of Structured Class-Labels~\ref{msrc_setting_3}.}\label{fig:msrc_scl}
\end{figure}

In this experiment we took the Setting~2~\ref{msrc_setting_2} and added approach from~\cite{Kontschieder2011}  (description of the method can be found
in~\ref{scl_description}) which helps to improve the output segmentations results by removing a lot of noise and making the labeling more consistent.
Though the improve in terms of numbers is not that much significant ($\sim$1\%), but the improve in visual segmentation quality is evident.
Because this method works only in the label space and does not consider features or original image, or even the probability distribution for each pixel,
it is not able to correct wrong guesses, which can be the output of the classification process.

In this experiment the feature settings were the same as in~\ref{msrc_setting_2}. The width of a square label patch was chosen to be 7 pixels.

Figure~\ref{fig:msrc_scl} (forth column) shows some results of this approach. If compared to just Random Forest from the previous section which
does not consider labels' consistency among neighboring pixels, we observe significant reduction of label-noise.

\cite{Kontschieder2011} report total error of 39.2\%, which is better than we get, but this difference might be due to the fact that they used more
complicated features (CIE raw channel intensities, first and second order derivatives as well as HOG-like features, computed on L-channel). The 
main observation here is that even with the simplest features this approach allows to improve the results.

\subsection{Setting 4: Random Forest with Texton Features}
\label{msrc_setting_4}
Method proposed in~\cite{Shotton2009} is used in~\cite{Krahenbuhl2011} and together they compile the current state-of-the-art method for general purpose
image segmentation. We implemented this method as described in the original article~\cite{Shotton2009} with the main difference, that we used Random 
Forest instead of Boosting
as the basic classifier. We augmented our implementation of Random Forests to be able to work with the new features (detailed description can be found
in~\ref{texton_features})

In this experiment we precomputed textons for both train and test images, so the measured running times do not reflect the duration of this process.
As proposed by the authors we also used subsampling of the texton maps in order to decrease memory requirements. This does not effect the accuracy,
because while computing Integral images we aggregate information of the whole patch that is being subsampled, so there is no loss of texton information,
we just correspondingly decrease the spatial resolution of the output classifier.
Due to the specifics of random nature of Random Forests, in each spit node we sampled 10 random rectangles for each of 400 textons in order to be sure not to
miss important information. Obviously, this results in increased training time because of the increased search space. But the testing time still stays very
low.

Figure~\ref{fig:msrc_texton_boost} (third column) shows some example segmentations for this approach. One can notice, that the resulting segmentation
is quite noisy and does not preserve object boundaries. So, this approach is good for quickly locating object in the scene, but it is not that faithful
for determining exact object boundaries, so some additional post-processing step (at least a simple CRF as in the original paper) is absolutely
necessary.

\cite{Shotton2009} report total error of $\sim$30\%. But it is not clear from the article with which parameters they got this result. We downloaded the code
the authors provide with this article, ran it and the result was 37.3\%, which is almost exactly the same, as what we achieved.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/1_9_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/1_9_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/1_9_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/1_9_s_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/3_26_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/3_26_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/3_26_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/3_26_s_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/7_21_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/7_21_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/7_21_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/7_21_s_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/14_20_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/14_20_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/14_20_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/14_20_s_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/16_12_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/16_12_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/16_12_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/16_12_s_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/20_17_s}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/20_17_s_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/20_17_s_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/textonboost_images/20_17_s_map}
 \end{subfigure}
 \caption[Random Forests with Textons and FC-CRF]{{\bf Random Forests with Textons and FC-CRF}.
 Columns denote from left to right: original image, ground truth image, output labeling of Random Forest with Texton features, ouput labeling
 of fully-connected CRF method applied on top of the result of Random Forest with Texton features.}
 \label{fig:msrc_texton_boost}
\end{figure}

\subsection{Setting 5: Random Forest with Texton Features and Fully-Connected CRF (FC-CRF)}
\label{msrc_setting_5}
This approach was proposed in~\cite{Krahenbuhl2011} and, same as Structured Class-Labels method, can be seen as a method of enhancing resulting labeling
of images by introducing a fully-connected CRF over the image pixels and, which is most important, allowing to perform inference into such complicated
graph in linear time. Unlike the Structured Class-Labels method, this approach considers both the feature-transformed image and the probability distributions
of each pixel which is the output of the unary classifier. Basically, this means that this approach can be applied on top of any classification
algorithm, which is able to produce probability distributions. In our experiments we used the code provided by the authors and applied it to the output of
Random Forest with Texton Features from the previous section. As this approach does not change anything in the training process and is only applied while
testing, the training time does not change at all. As a result we observe a significant boost (almost -10\% for total error) in the overall
classification accuracy.

Figure~\ref{fig:msrc_texton_boost} shows some example labelings of this approach. One can notice, that the segmentation has very fine details in terms of
object boundaries, unlike over-smoothed object boundaries for ordinary CRF approaches in which each pixel is connected only to a small number of
neighboring pixels.

\subsection{Discussion}

The conducted experiments show that the more advanced classification approach always performs better in terms of accuracy. But on the other hand
this comes at the cost of proportionally increasing the running time of the algorithm. For example, as it follows from Table~\ref{tab:msrc_comparison}
the method of Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011} performs almost twice as better as the best accuracy results achieved by our implementation of
Random Forest with Texton features and fully-connected CRF. But on the other hand the former method requires almost a day for training and testing
of running on a very powerful machine, while for the latter it takes just a bit more than 10 minutes for training and less than 5 minutes for testing.
And the main reason for better performance of Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011} is that they use a much richer set of features. But we overcome
this difference by using advanced features for road detection in the following experiments, while retaining low running time. We also choose our 
implementations, because they are based on Random Forests, which are better suitable for on-line learning than boosting, which is
used in Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011}

\section{Experiments on the New Test Set}

For notational convenience, from here on we use the word \emph{old} when we refer to the training and testing datasets from~\cite{Wojek2008},
and \emph{new} when we mean the introduced more challenging dataset. In all the following experiments we performed training on the old  training set.

We performed a number of experiments on the dataset proposed in Chapter~\ref{Chapter4}. First of all, we show that the new dataset is indeed more
challenging not only from our personal point of view, but also for the state-of-the-art method for general purpose image segmentation of
Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011}. This shows that standard approaches which learn the class distribution from the training data
can perform well on the data which shares the same distribution, but degrade in accuracy if the distribution changes in the testing data.
Then we show that some of the standard approaches totally fail when the distribution changes. And also that features are very important
to be chosen carefully for a particular application.


\subsection{State-of-the-art Segmentation Algorithm}
\label{sec:sota_new_set}
In order to show that the introduced data-set is indeed a more difficult challenge that the old one, we applied the current state-of-the-art
segmentation algorithm~\cite{Krahenbuhl2011} pipeline to both sets. The pipeline consists of two main steps: the initial segmentation is done using some
unary classifier, then the fully-connected CRF algorithm as applied to it. The authors used their own implementation of TextonBoost~\cite{Shotton2009}
(the corresponding code can be found at the following location \url{http://graphics.stanford.edu/projects/densecrf/textonboost/}). We also used this code,
and thanks to the fact, that the code is well-written and, though contains almost no comments, is easy to understand, we slightly changed the 
code to make it being able to work with our train and test datasets and, correspondingly, with our class-to-color mappings. After getting the unaries
from TextonBoost classifier, we applied the code (\ref{fc_crf_method}) for performing inference into fully-connected CRFs, which enhances 
the resulting segmentation results.

\begin{table}[t]
 \centering
 \begin{tabular}{|l|c|c|c|c|c||c|c|c|c|c|}
 \hline
  \multirow{2}{*}{Test set} & \multicolumn{5}{|c||}{Unary error, \%} & \multicolumn{5}{|c|}{FC-CRF error, \%} \\
  \cline{2-11}
   & \begin{sideways}Total\end{sideways} & \begin{sideways}Average\end{sideways} & \begin{sideways}Road\end{sideways} & \begin{sideways}Background\end{sideways} & \begin{sideways}Sky\end{sideways} & \begin{sideways}Total\end{sideways} & \begin{sideways}Average\end{sideways} & \begin{sideways}Road\end{sideways} & \begin{sideways}Background\end{sideways} & \begin{sideways}Sky\end{sideways} \\
  \hline
  Old & 1.9 & 2.5 & 0.9 & 2.3 & 4.3 & 1.6 & 1.9 & 0.7 & 2.2 & 2.7 \\
  \hline
  New & 21.5 & 33 & 53.1 & 7.6 & 38.2 & 20.2 & 31.4 & 52.7 & 6.5 & 35 \\
  \hline
 \end{tabular}
  \caption{Comparison of Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011} semantic image segmentation algorithm on the old and the new test test. Training was performed
  on the old train set.}
\label{tab:old_new_comparison}
\end{table}

Figure~\ref{fig:easy_set_fc_crf} shows several, so to say, ``worst'' examples for the setting when the training and testing was performed on the 
old dataset. Even 
these ``worst'' images prove the numbers given in Table~\ref{tab:old_new_comparison}. The segmentation results are almost ideal. Even shadows or a bit
of dirt on the road does not create noticeable difficulties for the state-of-the-art classifier, even though this is a general purpose segmentation
algorithm and is not tuned for dealing with road scenes. But this accuracy comes at the cost of running time which comprises almost a day on a very
powerful machine. But all-in-all this experiment shows that the old test set is really not a problem for the state-of-the-art segmentation algorithms.

\begin{figure}[t]
\centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00100}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00100_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00100_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00100_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00132}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00132_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00132_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00132_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00136}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00136_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00136_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00136_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00140}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00140_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00140_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/easy_set/00140_map}
 \end{subfigure}
 \caption[State-of-the-art on the old test set]{{\bf State-of-the-art on the old test set}.
 Columns denote from left to right: original image, ground truth image, output of the unary classifier, enhanced segmentation after applying
 the FC-CRF algorithm.}\label{fig:easy_set_fc_crf}
\end{figure}

The second row of Table~\ref{tab:old_new_comparison} shows the numerical results for the state-of-the-art when trained on the old and tested on the new
dataset. Total and average errors prove that the new test set is around 10 times harder than the old one. Per class errors show that the main difficulty
for the classifier is the ``road'' class: less than every second pixel belonging to this class gets labeled correctly. And this is quite expected,
because the ``road'' in the new test set barely resemble the ``road'' samples which can be seen in the training data. And as the state-of-the-art method
relies more on the appearance features it evidently has problems with correctly classifying ``road'' pixels. But, certainly, correct segmentation of the
``road'' is the prime aim for any classifier, so the new test set in fact introduces new challenges. ``background'' gets classified very well, but this
can be explained by the fact that it is the most representative class in both train and test datasets so for any classifier it is always safer to predict
``background'', because even such random choice has the highest probability of being correct just by chance compared to the other classes. It is
interesting to notice that the sky also has quite a large test error, though its appearance shouldn't be changing much when going from one dataset to
another. So, putting ``sky'' into a separate class rather than into the ``background'' class, as it is done in other approaches (like~\cite{Alvarez2010}),
makes the whole task of classification even more difficult.

In the following pages we show some particular examples of the segmentation results we get with the state-of-the-art trained on the old training set
and tested on the new testing set. We used exactly the same parameters as those when we did the experiment on the old training and testing sets.
The testing was carried out on the whole new test set, but just for the sake of increasing convenience we show good and fail cases for two parts of
our new test set separately.

Figure~\ref{fig:fc_crf_good_autumn} shows some results of the state-of-the-art segmentation algorithm applied to the ``autumn'' part of the new dataset.
Despite the fact, that these images clearly differ very much from the training ones, the state-of-the-art manages to detect the road completely covered 
with yellow leaves, or the road which is not even covered with asphalt, or even some way (which cannot be even called a road) through forest. We think,
that this successful cases are due the fact that the algorithm uses a reacher set of features (unlike in the original TextonBoost paper~\cite{Shotton2009}),
which also include location and HOG features, which must considerably help here.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00091}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00091_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00091_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00091_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00092}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00092_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00092_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00092_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00125}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00125_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00125_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00125_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00133}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00133_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00133_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00133_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00167}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00167_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00167_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00167_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00197}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00197_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00197_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00197_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00198}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00198_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00198_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00198_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00201}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00201_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00201_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00201_map}
 \end{subfigure}
 
 \caption[State-of-the-art on the new test set: Relatively good cases of ``autumn'' part]{
 {\bf State-of-the-art on the new test set: Relatively good cases of ``autumn'' part}.
 Columns denote from left to right: original image, ground truth image, output of the unary classifier, enhanced segmentation after applying
 the FC-CRF algorithm.}\label{fig:fc_crf_good_autumn}
\end{figure}

On the contrary Figure~\ref{fig:fc_crf_fails_autumn} shows some particular examples from the ``autumn'' series (certainly, there are more fails, than
shown here). While ``sky'' gets labeled more or less correctly in these images, but the algorithm totally fails in finding the road. But this is not
a surprise, because the given visual conditions are totally different from the training ones.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00088}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00088_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00088_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00088_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00101}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00101_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00101_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00101_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00107}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00107_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00107_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00107_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00175}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00175_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00175_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00175_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00163}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00163_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00163_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00163_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00129}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00129_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00129_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00129_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00140}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00140_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00140_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00140_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00168}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00168_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00168_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00168_map}
 \end{subfigure}

 \caption[State-of-the-art on the new test set: Fail cases on ``autumn'' part]{
 {\bf State-of-the-art on the new test set: Fail cases on ``autumn'' part}.
 Columns denote from left to right: original image, ground truth image, output of the unary classifier, enhanced segmentation after applying
 the FC-CRF algorithm.}\label{fig:fc_crf_fails_autumn}
\end{figure}

The following Figure~\ref{fig:fc_crf_good_winter} shows some examples of relatively good segmentation results from the ``winter'' part. Surprisingly
the state-of-the-art succeeds in finding the road fully covered with snow, which are for sure totally 
different from roads seen in the training set from the point of view of their appearance. Again, we think that this happens due to extended feature set,
which includes not only appearance information. Figure~\ref{fig:fc_crf_fails_winter} shows some failure cases of the state-of-the-art applied to the
``winter'' part of the new dataset. Same as with ``autumn'' failure cases, here ``sky'' also gets labeled somewhat correctly, but the road is not
detected at all.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00209}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00209_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00209_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00209_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00216}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00216_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00216_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00216_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00231}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00231_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00231_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00231_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00236}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00236_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00236_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00236_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00248}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00248_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00248_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00248_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00258}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00258_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00258_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00258_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00289}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00289_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00289_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/good_cases/00289_map}
 \end{subfigure}
 \caption[State-of-the-art on the new test set: Relatively good cases on ``winter'' part]{
 {\bf State-of-the-art on the new test set: Relatively good cases on ``winter'' part}.
 Columns denote from left to right: original image, ground truth image, output of the unary classifier, enhanced segmentation after applying
 the FC-CRF algorithm.}\label{fig:fc_crf_good_winter}
\end{figure}

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00206}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00206_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00206_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00206_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00212}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00212_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00212_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00212_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00217}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00217_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00217_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00217_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00220}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00220_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00220_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00220_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00226}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00226_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00226_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00226_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00246}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00246_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00246_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00246_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00247}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00247_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00247_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00247_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00294}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00294_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00294_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.24\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/new_set_examples/fails/00294_map}
 \end{subfigure}
 \caption[State-of-the-art on the new test set: Fail cases on ``winter'' part]{
 {\bf State-of-the-art on the new test set: Fail cases on ``winter'' part}.
 Columns denote from left to right: original image, ground truth image, output of the unary classifier, enhanced segmentation after applying
 the FC-CRF algorithm.}\label{fig:fc_crf_fails_winter}
\end{figure}

\clearpage


\subsection{Simple Features}
\label{sec:same_setting_new_set}

We started our experiments on the new test set by first applying segmentation algorithms from part~\ref{msrc_experiments} using the same features and
all the parameters for the corresponding approaches as there.
The results can be seen in Table~\ref{tab:new_set_normal_features}. There is not so much can be said about it. Obviously, the first three approaches
cannot even slightly compete with the state-of-the-art, because they use simple CIELab values as features, and, as expected, appearance-based models
cannot faithfully generalize over the visual conditions not present in the training set. Basically, the road test error numbers for this approach prove
this argument, because it always stays extremely huge. ``sky'' gets labeled a bit better by Random Forest on feature patches and Structured Class-Labels
approaches, but again all the three methods just assign ``background'' label when they don't know what to do.

\begin{table}[t]
 \centering
 \begin{tabular}{|l|c|c|c|c|c||c|c|c|c|c|}
 \hline
  \multirow{2}{*}{Method} & \multicolumn{5}{|c||}{Unary error, \%} & \multicolumn{5}{|c|}{FC-CRF error, \%} \\
  \cline{2-11}
   & \begin{sideways}Total\end{sideways} & \begin{sideways}Average\end{sideways} & \begin{sideways}Road\end{sideways} & \begin{sideways}Background\end{sideways} & \begin{sideways}Sky\end{sideways} & \begin{sideways}Total\end{sideways} & \begin{sideways}Average\end{sideways} & \begin{sideways}Road\end{sideways} & \begin{sideways}Background\end{sideways} & \begin{sideways}Sky\end{sideways} \\
  \hline
  Random Forest & 35.9 & 61.5 & 90.1 & 6.9 & 87 & 34.7 & 63.7 & 95.2 & {\bf 2.2} & 93.8 \\
  RF/patches & 30.6 & 49.5 & 91 & 6.8 & 50.6 & 30.7 & 50.7 & 92.1 & 5.8 & 54.1 \\
  RF+SCL & 29.9 & 48.5 & 91.4 & {\bf 6.2} & 47.9 & - & - & - & - & - \\
  RF/Textons & 69.2 & 61.3 & 96.7 & 72.7 & {\bf 14.4} & 69.7 & 61.4 & 97.4 & 73.3 & {\bf 13.6} \\
  \hline
  \hline
  Kr\"ahenb\"uhl~\cite{Krahenbuhl2011} & {\bf 21.5} & {\bf 33} & {\bf 53.1} & 7.6 & 38.2 & {\bf 20.2} & {\bf 31.4} & {\bf 52.7} & 6.5 & 35 \\
  \hline
 \end{tabular}
  \caption{Comparison of approaches described in Section~\ref{msrc_experiments}. For a comparison results of Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011}
  are also provided.
  Bold font highlights the best numbers.}
\label{tab:new_set_normal_features}
\end{table}

An interesting observation can be made regarding the approach based on Random Forest and Texton~\ref{texton_features} features. This approach showed
very good results on the MSRC dataset~\ref{tab:msrc_comparison} and, in fact, performs extremely well (Figure~\ref{fig:old_set_texton_boost})
on the old testing set, showing total error numbers $\sim$6\% for the unaries and $\sim$4\% after applying the fully-connected CRF approach, 
but here it simply fails everything. Figure~\ref{fig:new_set_textonboost_fails} shows some results for this approach applied to the new testing set. 
It is interesting that the algorithm performs quite good segmentation, but assigns totally wrong labels. 

We think that this is due to the fact how Texton features work. Both Figures~\ref{fig:new_set_textonboost_fails} and~\ref{fig:old_set_texton_boost} 
show texton maps for each input image, where colors denote different textons and are the same for both figures. 
If we compare them, then texton maps of old test images show the expected uniform assignment of ``road'' and ``sky'' pixels, whereas texton maps for the 
new test images contain almost only noise. And also due to the fact that appearance of ``road'' changes dramatically when going from old train to new 
test data and, probably, whitening parameters and cluster centers computed on the old train set do not suit the test data, 
and pixels from the new test images are simply assigned to completely wrong cluster centers even after whitening. 
These textons were designed by the authors for the MSRC dataset, in which train and test sets
share the same appearance and such clusterization works well for it, but does not work in our case.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00000}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00000_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00000_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00000_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00000_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00003}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00003_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00003_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00003_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00003_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00014}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00014_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00014_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00014_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00014_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00129}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00129_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00129_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00129_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00129_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00207}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00207_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00207_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00207_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00207_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00218}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00218_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00218_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00218_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00218_map}
 \end{subfigure}
 \caption[Random Forest with Texton features and the new test set]{
 {\bf Random Forest with Texton features and the new test set}. Though the algorithm segments out the ``road'' and ``sky'' classes quite well,
 it assigns wrong labels. Texton maps show particular problems of clusterization, because such assignments for road are totally different from
 the ones seen in the training data.
 Columns denote from left to right: original image, texton map for it, ground truth image, output of the unary classifier, enhanced segmentation 
 after applying the FC-CRF algorithm. For texton maps colors denote different textons (cluster centers).}
 \label{fig:new_set_textonboost_fails}
\end{figure}

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00001}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00001_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00001_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00001_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00001_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00002}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00002_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00002_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00002_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00002_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00023}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00023_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00023_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00023_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00023_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00045}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00045_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00045_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00045_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00045_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00067}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00067_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00067_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00067_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00067_map}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00086}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00086_TM}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00086_GT}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00086_cl}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/texton_boost_new_set/00086_map}
 \end{subfigure}
 \caption[Random Forest with Texton features and the old test set]{
 {\bf Random Forest with Texton features and the new test set}. The segmentation results on the old testing set are almost perfect. Texton maps
 show almost uniform assignment.
 Columns denote from left to right: original image, texton map for it, ground truth image, output of the unary classifier, enhanced segmentation 
 after applying the FC-CRF algorithm. For texton maps colors denote different textons (cluster centers).}
 \label{fig:old_set_texton_boost}
\end{figure}

\clearpage

\subsection{Advanced Features for Road Detection}
\label{sec:adv_features_new_set}

Then we conducted a number of experiments on the new testing set using the above described classifiers but this time with the advanced features for
road detection from original paper by Christian Wojek and Bernt Schiele~\cite{Wojek2008} (described in~\ref{advanced_features}). Then numerical results 
are given in Table~\ref{tab:new_set_christian_features}. As it follows
from the table, even a simple ordinary Random Forest (with the help of fully-connected CRFs), but which uses advance features, can successfully compete 
with very sophisticated algorithms, and the original method of Wojek \etal~\cite{Wojek2008}. This experiment shows that feature engineering is an essential part of the designing process of a good classifier.

\begin{table}[ht]
 \centering
 \begin{tabular}{|l|c|c|c|c|c|}
 \hline
  \multirow{2}{*}{Method} & \multicolumn{5}{|c|}{Error, \%} \\
  \cline{2-6}
   & Total & Average & Road & Background & Sky \\
  \hline
  RF & 20.1 & 27.7 & 43.8 & 10.5 & 29.1 \\
  SCL & 19.9 & 27.6 & 38.6 & 11.1 & 33.1 \\
  RF+FC-CRF & {\bf 18.8} & 24.7 & 40.8 & 11.0 & {\bf 22.2} \\
  \hline
  \hline
  Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011} & 20.2 & 31.4 & 52.7 & {\bf 6.5} & 35 \\
  Wojek \etal~\cite{Wojek2008} & 19.2 & {\bf 23.9} & {\bf 34.2} & 13.2 & 24.5 \\ 
  \hline
 \end{tabular}
  \caption{Comparison of different approaches based on Random Forest with advanced features for road detection, and Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011}
  approach.
  Bold font highlights the best numbers.}
\label{tab:new_set_christian_features}
\end{table}

\subsection{Discussion}
The results presented in Table~\ref{tab:old_new_comparison} show that our proposed dataset is almost 10 times harder than the older one 
from~\cite{Wojek2008}. This introduces new challenges into the segmentation community.

In Section~\ref{sec:same_setting_new_set} we showed that the Random Forest classifier with Texton features, which showed one of the best results on the 
MSRC dataset (Table~\ref{tab:msrc_comparison}), totally fails when the underlying class distribution changes with time or with datasets. This is a 
particular example of the fact that adaptation is an essential technique for handling such changes.

Section~\ref{sec:adv_features_new_set} shows the importance of careful feature selection for a particular task. Based on the obtained results in
Table~\ref{tab:new_set_christian_features} we decided to take pure Random Forest together with the advanced features, because this setting shows
accuracy comparable (and even better for some classes) with Kr\"ahenb\"uhl \etal~\cite{Krahenbuhl2011}. But Random Forest has extremely little
training and testing time. And using pure Random Forest allows to perform adding of new samples in on-line learning much easier and faster.

\section{On-line Learning}
\label{sec:online_learning}

On-line learning is a method of incorporating arriving information at the time of testing. It is based on the fact that we put new samples, which 
have just been classified by the algorithm, together with the predicted label straight into the classifier and re-train it.
It was shown in~\cite{Saffari2009} that on-line learning converges to off-line one, so pure on-line method can be seen as just a speeding up technique.
Instead we use, as we call it, batched learning, where we take a number of consequent images (in all experiments we fixed the size of a batch to 10
images) and use process them by the algorithm.

We also combine off-line learning together with on-line learning by first training a classifier on the old training set (off-line part) and then refine it
by adding new samples at the testing time (on-line part). Correspondingly, we call the old training set, which is used for training in off-line manner,
as \emph{off-line set}, and the new testing set, which is used for on-line learning, as \emph{on-line set}. And the classifiers, which was trained only
on the off-line set or on both sets as \emph{off-line} and, correspondingly, \emph{on-line} classifier.

For all the following experiments we randomly permuted the on-line set and saved the permuted indexes, in order to imitate a random input to all the
methods and to be sure that they all get the same input in order to be fully comparable.

\subsection{Naive Approach}

The naive approach (Section~\ref{sec:naive_theory}) is based on performing segmentation of a new batch of images, then selecting a 
number of pixels of each class and adding them into the classifier, which is later re-trained on the old and new new samples. 

\begin{figure}[ht]
 \centering
 \includegraphics[width=0.7\textwidth]{images/online_naive}
 \caption[Naive approach for on-line learning]{
 {\bf Naive approach for on-line learning}.
  X-axis is the number of new images that has been seen up to the current moment, Y-axis is the error rates (averaged over 3 runs)
  computed on the whole new testing set after processing the corresponding number of new images.}
 \label{fig:online_naive}
\end{figure}

\begin{figure}[ht]
 \centering
 \includegraphics[width=0.7\textwidth]{images/online_naive_as_if_real}
 \caption[Real on-line evaluation of the naive approach]{
 {\bf Real on-line evaluation of the naive approach}.
 Solid lines denote on-line classifier and dashed lines its off-line counterpart.}
 \label{fig:online_naive_as_if_real}
\end{figure}

Figure~\ref{fig:online_naive} shows the behavior of test errors for each class, as well as total and average, depending on how many of the on-line
images the algorithm has seen so far. In this experiment we carried out accuracy evaluation on the whole on-line dataset after every other lately processed
batch of on-line files. The very first values correspond to error rates of an off-line classifier (\ie the one, which was trained solely
on the off-line data). As it follows from the chart even the most simple on-line learning approach helps to considerably decrease test error for
the ``road'' class, as well as ``sky''. ``background'' error increases slightly, but the Average and Total error decrease in general.

In order to evaluate the real on-line accuracy of an on-line classifier we propose to conduct an experiment, which simulates the real on-line scenario
of new data arrival and testing. This method implies computing error rates not on the whole on-line set, but exactly on the part of it, which has just
arrived. It exactly corresponds to the real-world application, when a new image arrives and we want to be sure to carry out accurate segmentation
particularly on this image, rather than improving segmentation of the images which are already ``the past'' regarding current moment.
Figure~\ref{fig:online_naive_as_if_real} shows results for such evaluation. As it follows from the plot, on-line classifier indeed performs better, than
its off-line counterpart, especially for the ``road'' class: the ``road'' on-line curve is always (and sometimes considerably) lower than the off-line one.

\subsection{Adding Constraint in the Form Prior Labeling}

An extension of the naive approach would be to use some prior information, which can be computed on the off-line set. \cite{Alvarez2012} propose to compute
class-histogram on the off-line data, then normalize it per-pixel and use it as a prior distribution to weigh the output probability distribution 
of the classifier at testing time, which should help to decrease the number of false positives being accepted.

\begin{figure}[ht]
 \centering
 \includegraphics[width=0.7\textwidth]{images/online_alvarez}
 \caption[On-line learning with the prior labeling constraint]{
 {\bf On-line learning with the prior labeling constraint}.
  X-axis is the number of new images that has been seen up to the current moment, Y-axis is the error rates (averaged over 3 runs)
  computed on the whole new testing set after processing the corresponding number of new images.
 }
 \label{fig:online_alvarez}
\end{figure}

\begin{figure}[ht]
 \centering
 \includegraphics[width=0.7\textwidth]{images/online_alvarez_as_if_real}
 \caption[Real on-line evaluation of the prior-constrained approach]{
 {\bf Real on-line evaluation of the prior-constrained approach}.
 Solid lines denote on-line classifier and dashed lines  its off-line counterpart.}
 \label{fig:online_alvarez_as_if_real}
\end{figure}

Figure~\ref{fig:online_alvarez} shows error rates depending on how many of the on-line images the algorithm has seen so far. This approach considerably
decreases ``road'' error making it almost 2 times less. But on the other hand, ``background'' error in this case considerably increases, although
the overall Total and Average errors go down, as well as ``sky'' error. The reason for such behavior can be that this algorithm tries to make any
segmentation look close to the prior labeling (Figure~\ref{fig:prior_labeling}) with some deviation, but this deviation may not be enough for some particularly
difficult cases, which we have a lot in our on-line dataset. For a real-life application the segmentation algorithm should not only correctly find
the ``road'', but also its boundaries which is the ``background'' class. Otherwise, it would be easy just to mark all pixels in the lower part of
an image as ``road'', resulting in low error rate for this class, but making such systems useless in practice.

As in the previous section, Figure~\ref{fig:online_alvarez_as_if_real} shows results for the real on-line evaluation of the approach. The accuracy of
``road'' classification improves great, but it comes at the cost of considerable increase in the ``background'' error.


\subsection{Bayesian Model Update for Scene Segmentation under Structured Scene Prior}
\label{subsec:bayesian_model}

In Section~\ref{sec:bayesian_theory} we proposed a new way of incorporating unlabeled data, based on Bayesian tracking formulations (\cite{Isard1998}).
But in contrast to previous work, we track an evolving model over time and use a scene segmentation prior in order to avoid model drift.

In this, experiment we used 5 particles each of which being a Random Forest classifier with advanced features for road detection, but, in general,
any other classifier can be used as a particle. Bayesian formulation of the approach gives mathematical ensures that increasing the number of 
particles to infinity will guarantee that the tracking algorithm will not miss the target distribution. But increasing the number of particles makes
the whole system very computationally demanding.

Figure~\ref{fig:online_bayesian} shows error rates in dependence on how many of the on-line images the algorithm has seen so far.
As it follows from the plot, the tracking converges quite quickly and stays at the same level almost without any variation. Only ``sky''
error is constantly going down during the whole observation period.

Figure~\ref{fig:online_bayesian_as_if_real} shows results for the real on-line evaluation of the approach. It is remarkable, that the error rate of 
the ``road'' class stays always considerably below the off-line reference. Unlike for the naive on-line approach (Figure~\ref{fig:online_naive_as_if_real})
the error of the ``sky'' class stays always below the off-line reference. The ``background'' curves almost coincide for the on-line and off-line approaches.
And this totally corresponds to the original designing aim: to improve the detection of the road without sacrificing other classes.

\begin{figure}[ht]
 \centering
 \includegraphics[width=0.7\textwidth]{images/online_bayesian}
 \caption[Bayesian Model Update with Structured Scene Prior]{
 {\bf Bayesian Model Update with Structured Scene Prior}.
  X-axis is the number of new images that has been seen up to the current moment, Y-axis is the error rates (averaged over 3 runs)
  computed on the whole new testing set after processing the corresponding number of new images.
 }
 \label{fig:online_bayesian}
\end{figure}

\begin{figure}[ht]
 \centering
 \includegraphics[width=0.7\textwidth]{images/online_bayesian_as_if_real}
 \caption[Real on-line evaluation of the Bayesian Model Update with Structured Scene Prior approach]{
 {\bf Real on-line evaluation of the Bayesian Model Update with Structured Scene Prior approach}.
 Solid lines denote on-line classifier and dashed lines its off-line counterpart.}
 \label{fig:online_bayesian_as_if_real}
\end{figure}

Figure~\ref{fig:image_evolution_bayesian} presents some examples of image labelings' evolution in the process of adaptation. The labeling gets more 
consistent with time: segmentation ``holes'' in the ``road'' are getting smaller or eliminated at all, while the shape of the ``road'' is getting closer
to the ground truth image. And this happens without using ground truth images in the process of adaptation, but only by tracking the evolving class
distribution which allows to adapt to new severe conditions on-the-fly.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_000}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_001}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_002}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_003}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_019}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_020}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_021}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_022}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_GT}
 \end{subfigure}
 \\
 
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_000}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_001}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_002}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_003}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_019}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_020}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_021}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_022}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00014_GT}
 \end{subfigure}
 \\
 
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_000}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_001}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_002}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_003}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_019}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_020}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_021}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_022}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00210_GT}
 \end{subfigure}
 \\
 
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_000}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_001}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_002}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_003}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_019}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_020}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_021}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_022}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00188_GT}
 \end{subfigure}
 
 \caption[An example of image labeling evolution in on-line learning]{
 {\bf An example of image labeling evolution in on-line learning}. 
 First image presents the original image from the new dataset. Next four images show the segmentation after the first four iterations, and next four - 
 after the last fout iterations of our proposed Bayesian Model Update algorithm. The labeling becomes better and gets closer to the ground truth (the last
 image) with time.}
 \label{fig:image_evolution_bayesian}
\end{figure}

\subsection{Discussion}

Our experiments with on-line learning showed that adaptation to new conditions is a very helpful tool, which allows to improve stability in
situations when the underlying class distribution changes with time. Table~\ref{tab:on_line_converged} summarizes the error rates for the converged
on-line methods and an off-line one, which was just a Random Forest with advanced features for road detection trained only on the off-line set.

\begin{table}[ht]
 \centering
 \begin{tabular}{|l|c|c|c|c|c|}
 \hline
  \multirow{2}{*}{Method} & \multicolumn{5}{|c|}{Error, \%} \\
  \cline{2-6}
   & Total & Average & Road & Background & Sky \\
  \hline
  Naive & 18.8 & 24.4 & 35.6 & 11.9 & 25.7 \\
  Prior-constrained & 18.8 & {\bf 20.1} & {\bf 21.3} & 17.4 & 21.5 \\
  Bayesian & {\bf 17.1} & 21.0 & 32.9 & 11.7 & {\bf 18.5} \\
  \hline
  \hline
  Off-line (RF) & 20.1 & 27.7 & 43.8 & {\bf 10.5} & 29.1 \\
  \hline
 \end{tabular}
  \caption{Comparison of different approaches of on-line methods evaluated on the whole testing set after converging. For comparison results for
  the employed off-line method is provided.
  Bold font highlights the best numbers.}
\label{tab:on_line_converged}
\end{table}

The numbers show, that even a naive approach brings more than 1\% decrease in total error. For comparison: getting the same effect requires application
of the fully-connected CRF method (Table~\ref{tab:new_set_christian_features}). Prior-constrained on-line method results also in around 1\% decrease
of total error, but it just sacrifices the error rate of ``background'' in favor of ``road'', which is very very debatable whether it is useful in practice.

The proposed Bayesian Model Update method shows the best improve -3\% for total error, and results in more than 10\% decrease of ``road'' and ``sky'' errors,
while increasing the ``background'' error in just 1\%. Considering the difficultiness of the on-line testing set, we consider the obtained numbers to
be a considerable improvement over other approaches.
