\chapter{Introduction}
\label{Chapter1}

\section{Motivation}
Scene segmentation, as the task of separating an input image into homogeneous regions each having a predefined meaning (class-label),
is one of the core problems in Computer Vision. Image segmentation helps to simplify an input image and analyze it, in order to 
help a machine to understand what is depicted there and to allow it to use this information in its work. This is, in particular, a crucial
property for systems which are used for navigation of robots or cars in the environment, which is in turn can be used to help people to perform
safer or completely autonomous driving or have other important civil application.

Figure~\ref{fig:seg_example} shows, probably, one of the most important applications of image segmentation in the driving assistance systems.
In this case image segmentation can help to turn complicated for understanding road scenes' images into simpler ones, which in turn can be processed
by an on-board computer and can, for example, hint the driver about possible dangerous situations on the road and help to avoid colliding with other
vehicles and, most important, pedestrians.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.45\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/seg_example}
 \end{subfigure}
 \begin{subfigure}[c]{0.45\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/seg_example_GT}
 \end{subfigure}
 \caption[Application of image Segmentation in driving assistance]{
  {\bf Application of image Segmentation in driving assistance}. Left: the original image from an on-board camera installed on a car.
  Right: handmade segmentation of the original image.
  Image segmentation helps to simplify the input image in order to improve understandability and outlines, for example, the road surface (blue color), 
  other vehicles (orange), and pedestrians (green), which can help make driving safer.
  }\label{fig:seg_example}
\end{figure}

Image segmentation can also have other fields of application. For example, it can be used as the lower layer in different object detection algorithm
generating proposals for where objects belonging to certain classes might be in the image. Most detectors are based on the sliding-window approach,
which means that if there exist a way to perform initial localization of regions of interest, this can significantly reduce the running time of the
detection algorithm and improve their accuracy.

Being an important problem in Computer Vision, image segmentation has been studied carefully for a long time and a number of algorithms have been
proposed to deal with it. The most conventional approaches are based on learning the underlying class distribution on some training set, and then
predicting class-labels for previously unseen instances based on the learned distribution. The main assumption, which must hold in order for such 
methods to work, is that this class distribution stays the same for the unseen instances. Is this does not hold then these methods start to experience 
certain difficulties which result in degrade of the accuracy. In real-world application there can be situations, when this assumption might not hold. 
For example, a car was driving along a highway, but then 
turns into a country road. Though the surface the car is going on now can still be called a road, but its appearance completely differs from
the asphalted highway. Now if we take, for example, a standard classifier which learned the class distribution on asphalted road samples will
have difficulties on the country road as the appearance of the road and the underlying class distribution has changed considerably.

In order to deal with possible changes of the class distribution on-line learning techniques can be used. The main idea behind them is that
they try to give algorithms the ability to adapt themselves to such changes, improving their robustness to previously unseen conditions, but
also ensuring that the algorithm does not experience \emph{model drift}, \ie learning a distribution which differs too much from the original one.

In this thesis we want to explore on-line learning techniques and their particular application to the task of image segmentation. 
We are aiming for tracking an evolving target distribution over models. An example of such application is presented in 
Figure~\ref{fig:image_evolution_teaser}, which shows how image segmentation of a difficult image becomes better as algorithm performs adaptation with time.
As all the 
datasets which are in use nowadays do not exhibit the level of variation in visual appearance we want to test, we collected new road scenes' dataset
and manually labeled it. We implemented a number of modern approaches which do not account for distribution changes and tested them on the 
new dataset, employing simple features as well as features specially designed for road detection. We experimented with existing
on-line learning techniques and proposed our way of improving stability of on-line learning algorithms using Bayesian Model Update 
under Structured Scene Prior.

\begin{figure}[t]
 \centering
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_000}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_001}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_002}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_003}
 \end{subfigure}
 \\
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_019}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_020}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_021}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_022}
 \end{subfigure}
 \begin{subfigure}[c]{0.19\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/results/image_evolutions/00129_GT}
 \end{subfigure}
 
 \caption[An example of image labeling evolution in on-line learning]{
 {\bf An example of image labeling evolution in on-line learning}. 
 First image presents the original image from the new dataset. Next four images show the segmentation after the first four iterations, and next four - 
 after the last fout iterations of our proposed Bayesian Model Update algorithm. The labeling becomes better and gets closer to the ground truth (the last
 image) with time.}
 \label{fig:image_evolution_teaser}
\end{figure}

The contributions of this work are:
\begin{itemize}
 \item a new more challenging road scenes dataset;
 \item a new Bayesian Model Update under Structured Scene Prior approach, which allows to tack an evolving distribution and therefore perform adaptation
 to new conditions.
\end{itemize}

\section{Related Work}
In order to experiment with adaptive techniques we first needed to choose an appropriate classifier and features. From the classifier
we needed good accuracy, low training and testing time and initial robustness to noise in the samples' labels, as our approach to performing adaptation
is based on on-line learning which uses predicted label in the process of retraining and they can be noisy. We also investigated in how Conditional
Random Fields approaches can help to improve segmentation in adverse conditions, as well as other approaches which work with structured label space.

{\bf Unary Classifiers} \qquad The idea of combining classifiers (boosting) in order to improve their combined (boosted) quality is due to~\cite{Schapire1990}. A few years later the 
first boosting
algorithm was proposed in~\cite{Freund1995}, which gave birth to very popular boosting algorithms called AdaBoost and GentleBoost. For a long time
boosting was a de facto standard classifier for any real-time segmentation algorithm (\cite{Shotton2009, Osa2001}).
Random Forests were introduced in~\cite{Breiman2001} and further explored in~\cite{Geurts2006} and showed very good accuracy (\cite{Shotton2008})
and speed of both evaluation and testing (\cite{Sharp2008}) due to easy parallelization, and thanks to these properties they start to become
a default choice for a basic classifier in image segmentation (\cite{Brostow2008, Shotton2008, Kontschieder2011}). In particular, \cite{Brostow2008}
used Random Forests to perform image segmentation of videos captures on roads.

{\bf Conditional Random Fields} \qquad The first application of Conditional Random Fields in Semantic Image Segmentation can be regarded to~\cite{Lafferty2001}, who proposed
to use CRFs to improve segmentation results. The work~\cite{Ladicky2009} extended the conventional CRF formulation by adding higher order
potentials on image segments to improve consistency between them. However, the accuracy of these latter approach is restricted by 
the accuracy of unsupervised image segmentation, which is used to locate the regions on which the model operates. The most recent 
work of~\cite{Krahenbuhl2011} proposes to use a fully-connected CRF over the image pixels in order to use information contained in
the image itself to improve segmentation. This approach helps to preserve very fine details of objects' borders, whereas conventional
CRF approaches tend to smooth image boundaries. \cite{Krahenbuhl2011} is currently state-of-the-art algorithm for semantic image segmentation.
It is worth mentioning that it is based on the method of~\cite{Shotton2009}, the main part of which are Texton features, which we employ in this work.
We also employ advanced features for road detection from~\cite{Wojek2008}.

While the above mentioned approaches consider only feature space of an image in order to improve segmentation results, \cite{Kontschieder2011}
propose to use not the single pixel's label, but rather to consider a certain labeling neighborhood around the pixel. This method allows
to learn frequently occurring in the training data labeling patterns, which certainly helps to make the segmentation more consistent. We think
that this method is particularly useful in the task of segmentation of road scenes, as there one can expect quite constant patterns of objects.

{\bf On-line Learning} \qquad The most obvious way of performing adaptation to changing conditions and, as a result, to the underlying class 
probability distribution
is to use the result of the currently segmented images to improve the classifier in a smart way, in order not to break what is working
correctly currently. This can be done by adding recently labeled samples into the classifier and retraining it. This process is called
\emph{on-line learning}. The first attempts were made in~\cite{Osa2001}. Later~\cite{Saffari2009} showed that on-line learning can be
done efficiently on the basis of Random Forest. They showed that with time the on-line classifier converges to the \emph{off-line} one
(\ie the one which was trained having access to all the samples). But in their approach they use samples together with labels,
whereas we're aiming for the scenarios when there are no any labels known, but only predictions of the current-state classifier are given.
Domain adaptation techniques~\cite{Saenko2010, Kulis2011} can help to adapt to evolving target domain distribution, but they also require at least some
sample instances with ground truth labels from the target domain.
The most recent work~\cite{Alvarez2012} considers exactly this setting, by adding new samples with the predicted labels constraining
this process by the prior labeling distribution. But in this work they perform testing on the CamVid~\cite{CamVid} dataset, which is 
quite out-of-date, and their dataset~\cite{Alvarez2010}, which has binary labeling into ``road'' and ``background'' and is not that challenging,
to our taste. Our proposed approach of improving stability and robustness of an on-line segmentation algorithm is based on the Condensation algorithm
from~\cite{Isard1998}, which was shown to be extremely useful in robotics application for robot localization in~\cite{Dellaert1999}.

\section{Outline}
The rest of this work is structured as follows:
\begin{itemize}
 \item Chapter~\ref{Chapter3} starts the thesis with a brief introduction/review of Conditional Random Fields
 with an accent on their particular application to the task of Semantic Image Segmentation. Section~\ref{sec:crf_definition} gives the definition of
 Conditional Random Fields and shows they are applied to image segmentation. We research the process of building a classifier from the very bottom layer,
 so the next Section~\ref{sec:features} describes which features we employed in this work (in particular: raw color features~\ref{raw_features}, 
 texture-layout features from~\cite{Shotton2009} for general purpose image segmentation~\ref{texton_features}, 
 and advanced features for road detection from~\cite{Wojek2008}~\ref{advanced_features}). 
 Section~\ref{sec:unaries} gives description of the two most popular nowadays unary classifiers Boosting~\ref{subsec:boosting} and 
 Random Forests~\ref{subsec:random_forests} and gives the pros and cons of each classifier. In our work we employ a number of algorithms which being 
 put on top of the unary classifier allow to enhance the quality of the output segmentation. Section~\ref{scl_description} describes the approach
 from~\cite{Kontschieder2011} (Structured Class-Label Prediction) which allows the unary classifier to work not on single pixel's labels but on the whole
 label patches. Section~\ref{fc_crf_method} describes the method from~\cite{Krahenbuhl2011} (Fully connected CRFs) which builds a fully-connected graph
 on the image pixels and using the output of the unary classifier allows to considerably improve segmentation results.
 
 \item Chapter~\ref{chapter_online} gives a description of on-line learning and outlines the benefits it can bring. Section~\ref{sec:naive_theory} presents
 the most simple approach for performing on-line learning, while Section~\ref{sec:alvarez_theory} contains our implementation of ideas from~\cite{Alvarez2012}
 on performing prior-constrained adding of new samples in the process of on-line learning. Section~\ref{sec:bayesian_theory} introduces our proposed
 approach for improving stability called Bayesian Model Update under Structured Scene Prior.
 
 \item Chapter~\ref{Chapter4} gives an overview of different datasets available in the image segmentation community and argues why they do not
 suit our research of domain adaptation.
 There we introduce a new road scenes' dataset which we gathered and labeled by hand giving a number of examples from it. 
 This dataset features extremely (in comparison to all other conventional road scenes' datasets) difficult (adverse) visual conditions.
 
 \item Chapter~\ref{Chapter5} describes all the experiments we conducted and gives the discussion of the achieved results together with our
 proposition on their improvement. Section~\ref{subsec:robust_to_noise} proves that Random Forests are robust to noisy labels
 and Section~\ref{subsec:rf_and_parameters} shows the influence and dependencies of different parameters of Random Forests. Section~\ref{msrc_experiments}
 presents the segmentation results of our implementations of the approaches described in Chapter~\ref{Chapter3} on the MSRC dataset. 
 Section~\ref{sec:sota_new_set} presents both numerical and visual results of evaluation of the state-of-the-art segmentation 
 algorithm~\cite{Krahenbuhl2011} on the dataset proposed in Chapter~\ref{Chapter4}.
 The evaluation experiments on the proposed dataset are followed by Section~\ref{sec:same_setting_new_set}, 
 which includes approaches from Chapter~\ref{Chapter3} and features from Sections~\ref{raw_features} and~\ref{texton_features}.
 Section~\ref{sec:adv_features_new_set} shows that Random Forest with advanced features from Section~\ref{advanced_features} can successfully
 compete with state-of-the-art segmentation algorithm~\cite{Krahenbuhl2011}.
 Section~\ref{sec:online_learning} presents results for two existing on-line learning approaches, whereas Section~\ref{subsec:bayesian_model} contains 
 results of our proposed approach on getting improvement and stability of an on-line learning method.
 
 \item Chapter~\ref{Chapter6} concludes the thesis summarizing all the results of our work and proposing directions for possible improvements.
 
 \item Appendix~\ref{AppendixA} gives a detailed algorithm of building a Random Forest, together with the algorithm for traversing test samples through
 a Random Forest.
\end{itemize}
